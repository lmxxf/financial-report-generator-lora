# 金融研报指标提取 LoRA

从金融研报段落中提取被深度分析的核心指标，输出结构化 JSON。

## 任务

输入一段研报段落，输出：
```json
{
  "analysis": "段落分析思路...",
  "metrics": [
    {"metric_name": "毛利率", "metric_type": "financial", "score": 0.95, "reason": "被深度分析"}
  ]
}
```

指标数量不固定，根据段落实际内容决定（1-4个）。

## 文件结构

```
├── train_lora.py              # QLoRA 训练 + 推理脚本
├── batch_infer.py             # 批量推理 + 简易评测
├── eval_script.py             # 三层评估脚本（语义匹配）
├── training_data_strategy.md  # 训练数据策略文档
├── sample_data.jsonl          # 50 条 demo 数据
├── test_cases.jsonl           # 50 条测试用例（6 个场景，v7 扩充 20→50）
├── test_cases_extra30.jsonl   # 新增 30 条测试用例（已合并入 test_cases.jsonl）
├── test_cases_results_v1.json  # v1 评测详细结果（14B/460条/5epochs/20条测试）
├── test_cases_results_v2.json  # v2 评测详细结果（14B/540条/5epochs/20条测试）
├── test_cases_results_v3.json  # v3 评测详细结果（32B/540条/5epochs/20条测试）
├── test_cases_results_v4.json  # v4 评测详细结果（32B/540条/5epochs/lr=5e-5/alpha=16/20条测试）
├── test_cases_results_v5.json  # v5 评测详细结果（32B/540条/5epochs/lr=2e-5/alpha=16/20条测试）
├── test_cases_results_v6.json  # v6 评测详细结果（14B/540条/5epochs/逐项排除式TypeB/20条测试）
├── test_cases_results_v7.json  # v7 评测详细结果（14B/590条/5epochs/逐项排除+边界加强/50条测试）
├── test_cases_results_v8.json  # v8 评测详细结果（14B/590条/8epochs/逐项排除+边界加强/50条测试）
├── test_cases_results_v9.json  # v9 评测详细结果（14B/590条/5epochs/全类型逐项排除/50条测试）
├── test_cases_results_v9.1.json # v9.1 评测详细结果（14B/590条/5epochs/回滚A&C+折中TypeD/50条测试）
├── test_cases_results_v10.json  # v10 评测详细结果（14B/590条/5epochs/计数前置/50条测试）
├── test_cases_results_v11.json  # v11 评测详细结果（14B/700条/5epochs/TypeD扩量46→156/50条测试）
├── test_cases_results_v12.json  # v12 评测详细结果（14B/700条/5epochs/编号列表格式TypeC+D/50条测试）⚠️ 退步
├── test_cases_results_v12.1.json # v12.1 评测详细结果（14B/700条/5epochs/分号枚举TypeA+C多指标/50条测试）⚠️ 退步
├── type_b_v2.jsonl             # C.C.改造后的Type B（逐项排除式analysis，152条）
├── type_b_extra50.jsonl        # 新增 50 条边界负样本（已合并入 data/type_b.jsonl）
├── data/                      # 完整训练集（700 条，v11）
│   ├── type_a.jsonl           # 标准正样本（270条）
│   ├── type_b.jsonl           # 边界负样本（202条，v7: 72→152→202）—— 逐项排除式analysis
│   ├── type_c.jsonl           # 数量变化样本（72条）—— 打破"永远提2个"
│   └── type_d.jsonl           # 混合类型专项（156条，v11: 46→156）—— 练 financial/business 分类
└── output/                    # 训练输出（.gitignore）
```

## 环境

DGX Spark (128GB) + docker 容器（nvcr.io/nvidia/pytorch:25.11-py3）。

```bash
# 进入容器（日常使用，记住这一条就够了）
docker start lora-train && docker exec -it lora-train bash

# 进去后
cd /workspace/lora
```

容器故障排查：

```bash
# 如果训练报错 "bf16/gpu not supported"，说明 GPU 没挂上
# 第一步：退出容器，重启试试
exit
docker restart lora-train && docker exec -it lora-train bash

# 第二步：如果重启还不行，删掉容器重建（数据不会丢，都是 -v 挂载的）
exit
docker stop lora-train && docker rm lora-train
docker run -it --gpus all --name lora-train \
  -v /home/lmxxf/work/financial-report-generator-lora:/workspace/lora \
  -v /home/lmxxf/work/models:/workspace/models \
  nvcr.io/nvidia/pytorch:25.11-py3 bash
# 重建后需要重新安装依赖（唯一丢的就是 pip 包）
pip install peft bitsandbytes trl

# 第三步：如果重建也不行，重启宿主机

# 进去后验证 GPU 是否正常
python3 -c "import torch; print(torch.cuda.is_available(), torch.cuda.get_device_name(0))"
# 应该输出：True NVIDIA GB10
```

首次创建容器（只需一次）：

```bash
docker run -it --gpus all --name lora-train \
  -v /home/lmxxf/work/financial-report-generator-lora:/workspace/lora \
  -v /home/lmxxf/work/models:/workspace/models \
  nvcr.io/nvidia/pytorch:25.11-py3 bash

# 容器内安装依赖
pip install peft bitsandbytes trl
```

| 库 | 作用 |
|---|---|
| peft | LoRA 实现，把全量微调变成只训几百万参数 |
| bitsandbytes | 8bit 量化加载，14B 模型从 28GB 压到 ~15GB |
| trl | HuggingFace 训练器，SFTTrainer + SFTConfig 处理 chat 格式对齐 |

## 为什么需要重新训练

原方案（260 条数据微调 Qwen3-14B）完美匹配仅 29%，详细诊断见 [training_data_strategy.md](training_data_strategy.md)，核心问题：

1. **260 条数据全部恰好 2 个指标** —— prompt 写死"数量严格控制：2个"，模型学会了凑数而不是判断
2. **158 条"不一致"中 45 条是字符串匹配误杀** —— "投资活动现金流" vs "投资活动净现金流"（相似度 0.93）被判错
3. **DeepSeek 的标注本身有问题** —— 它也在硬凑第二个指标

## 训练

基座模型：Qwen3-14B，8bit 量化加载（QLoRA）。

```bash
# 下载模型（中国镜像，在宿主机执行）
HF_ENDPOINT=https://hf-mirror.com huggingface-cli download Qwen/Qwen3-14B --local-dir /home/lmxxf/work/models/Qwen3-14B

# 容器内训练（用 50 条 demo 快速验证流程）
cd /workspace/lora
python train_lora.py train --model /workspace/models/Qwen3-14B --data sample_data.jsonl --epochs 3

# 用完整 540 条正式训练（v2）
python train_lora.py train --model /workspace/models/Qwen3-14B --data data/ --epochs 5
```

训练参数（默认值）：

| 参数 | 值 | 说明 |
|---|---|---|
| LoRA r | 16 | 低秩矩阵维度 |
| LoRA alpha | 32 | 缩放系数（alpha/r = 2，标准配比） |
| LoRA dropout | 0.05 | 防过拟合 |
| LoRA target | q/k/v/o/gate/up/down_proj | 全注意力层 + MLP，共 7 个模块 |
| trainable params | 64M / 14.8B (0.43%) | 只训练 LoRA 参数 |
| batch size | 2 × 8 (grad accum) = 16 | 有效批大小 |
| learning rate | 2e-4 | 余弦衰减（cosine） |
| warmup | 5% of total steps | 预热步数 |
| max grad norm | 0.3 | 梯度裁剪 |
| optimizer | paged_adamw_8bit | 8bit 优化器，省显存 |
| 混合精度 | bf16 | Blackwell 原生支持，比 fp16 数值更稳定 |
| gradient checkpointing | 开 | 用计算换显存 |
| max seq len | 2048 | 最大序列长度 |
| 量化 | 8bit (bitsandbytes) | QLoRA，int8_threshold=6.0 |
| 显存估算 | ~20GB | 14B 8bit + LoRA + 梯度 |
| save strategy | 每个 epoch | 保留最近 3 个 checkpoint |

训练好的 LoRA 权重：[lmxxf/financial-report-lora-qwen3-14b](https://huggingface.co/lmxxf/financial-report-lora-qwen3-14b)

## 工程细节基础教学

上面参数表里的每个数字背后都有工程考量。这里解释"为什么这么设"。

### Batch Size 的选择

有效 batch size = micro batch × gradient accumulation = 2 × 8 = 16。为什么是 16 而不是更大？

128GB 内存理论上 micro batch 能开到 8 甚至 16，有效 batch 到 64-128。但小数据集不适合大 batch：590 条数据 / batch=16 ≈ 每 epoch 37 次权重更新，5 epochs = 185 次更新。如果 batch=128，每 epoch 才更新 ~5 次，5 epochs = 25 次——模型还没学会就训完了。

另外 batch 翻倍 lr 也要跟着翻倍（线性缩放规则），否则等于学得更慢。小数据集用小 batch 噪声更大，反而帮助泛化、不容易过拟合。**590 条数据，batch=16 是合适的。**

### Gradient Accumulation（梯度累积）

那为什么不直接设 micro batch=16？因为 14B 模型显存放不下。实际一次只喂 2 条（micro batch），算 8 次梯度攒起来，再一次性更新权重。数学上等价于 batch=16，但显存只占 batch=2 的量。**穷人的大 batch。**

### Warmup（预热）

训练刚开始时 learning rate 从 0 慢慢涨到目标值（设了总步数的 5%）。因为 LoRA 权重刚初始化时接近随机，step 太大会把模型带沟里。就像冷车启动先怠速热一下。

### Cosine Decay（余弦衰减）

lr 涨到目标值后不是一直保持，而是按余弦曲线慢慢降到接近 0。开头学大方向，后期微调细节。配合 warmup 形成完整的 lr 曲线：`0 → 慢涨 → 峰值 → 慢降 → ~0`。

### Gradient Checkpointing（梯度检查点）

正常训练要存每一层的中间计算结果，反向传播时用。14B 模型几十层，中间结果巨大。开了 checkpointing 后只存几个关键层的结果，其他的需要时重新算。**用计算时间换显存**——DGX Spark 上能跑 14B QLoRA 就靠这个。

### Paged AdamW 8bit（分页优化器）

Adam 优化器要给每个参数额外存两个状态（一阶动量 m 和二阶动量 v），14B 模型这两组状态本身就占几十 GB。`8bit` 把这些状态从 fp32 压缩到 int8，省 4 倍显存。`paged` 是说 GPU 显存不够时自动把一部分挪到 CPU 内存，类似虚拟内存。

### LoRA Target Modules（目标模块）

LoRA 打了 7 个模块：`q_proj / k_proj / v_proj / o_proj`（注意力层）+ `gate_proj / up_proj / down_proj`（MLP 层）。

- **注意力层**（q/k/v/o）控制"看哪里"——模型如何分配注意力给输入的不同部分
- **MLP 层**（gate/up/down）控制"想什么"——模型看到信息后如何加工处理

只打注意力层 = 只改"看的方式"，加上 MLP = 连"想的方式"也改。打得越多效果越强，但也越容易过拟合。7 个全打是激进配置，适合数据量足够（500+）的场景。

### LoRA r 和 alpha 的关系

LoRA 的实际影响力 = `alpha / r`。r=16 是低秩矩阵的维度（越大表达能力越强），alpha=32 是缩放系数。`32/16 = 2` 是标准配比。

v3→v4 实验中把 alpha 从 32 降到 16（影响力从 2 降到 1），目的是让 32B 基座保留更多自身能力。结果：确实有改善但不够。这说明 LoRA 的"力度"需要和基座模型规模匹配。

### Epochs 和 Shuffle

每个 epoch 模型把全部训练数据"看"一遍。5 epochs = 看 5 遍。更多 epochs 能学得更深，但过多会过拟合（对训练数据背得滚瓜烂熟，对新数据反而不行）。

每个 epoch 开始前，DataLoader 会自动 **shuffle**（随机打乱）数据顺序。所以"先看 A 类再看 B 类"这种顺序偏差不存在——每轮看到的顺序都不一样。

### 8bit 量化加载（QLoRA 核心）

14B 模型 bf16 全精度需要 ~28GB，8bit 量化加载后 ~15GB。量化是**加载时逐层做的**——读一层 bf16 权重，立刻压成 int8 放进显存，不需要先把整个 bf16 模型展开。所以磁盘上文件是 28GB（bf16），但内存峰值远小于 28GB。

量化的代价是精度损失，但 LoRA 的可训练参数（64M）仍然是 bf16 全精度——只有被冻结的基座模型被量化了。这就是 QLoRA 的精髓：**基座省显存，LoRA 保精度**。

## 推理

```bash
python train_lora.py infer \
  --lora output/final \
  --title "盈利能力分析" \
  --text "公司毛利率同比提升2.3个百分点至35.8%，受益于产品结构优化和原材料成本下降。"
```

### 推理性能说明

当前推理用的是原生 `transformers` 的 `model.generate()`——最朴素的逐 token 自回归生成，没有任何优化。50 条测试在 DGX Spark 上跑约 2 小时，跑评测够用但不适合上线部署。

如果需要生产环境部署，推荐替换推理框架：

| 方案 | 加速比 | 说明 |
|---|---|---|
| **vLLM** | 5-10x | 推荐。原生支持 LoRA 热加载，推理代码需重写但改动不大 |
| **llama.cpp / GGUF** | 3-5x | 需要先把 LoRA 合并进基座再量化导出，适合纯 CPU 部署 |

vLLM 部署示例（需额外安装 `pip install vllm`）：

```bash
# 启动 vLLM 服务（支持 LoRA）
python -m vllm.entrypoints.openai.api_server \
  --model /workspace/models/Qwen3-14B \
  --enable-lora \
  --lora-modules financial-lora=output/final \
  --quantization bitsandbytes \
  --max-model-len 2048
```

然后用标准 OpenAI API 格式调用即可，吞吐量提升一个数量级。

## 评估

```bash
# 模糊匹配（零依赖）
python eval_script.py --pred predictions.jsonl --gold gold.jsonl

# 语义匹配（需要 sentence-transformers）
python eval_script.py --pred predictions.jsonl --gold gold.jsonl --method embedding

# 逐条查看
python eval_script.py --pred predictions.jsonl --gold gold.jsonl --detail
```

三层评估：
1. **核心命中率**（Recall）—— 标注里的核心指标，模型提到了几个
2. **精确率/召回率/F1** —— 多提了什么、漏了什么
3. **类型准确率** —— financial/business 分对了吗

批量评测（50 条测试用例，覆盖 6 个场景）：

```bash
python batch_infer.py --model /workspace/models/Qwen3-14B --lora output/final --test test_cases.jsonl
```

## 评测结果

### v12：Qwen3-14B / 700 条 / 5 epochs / 编号列表格式 Type C + D（50 条测试）⚠️ 失败实验

50 条测试，完美匹配 7/50（14%），宽松匹配 **22/50（44%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 0✅+4🟡/10 | **⬇️⬇️ 腰斩！**（v11: 9/10） |
| 多指标（2-3 个） | 1✅+3🟡/10 | ⬆️ 唯一涨点（v11: 3/10） |
| 边界判断（多数字少核心） | 1✅+3🟡/13 | ⬇️（v11: 6/13） |
| financial vs business 分类 | 0✅+3🟡/7 | 持平 |
| 空输出（背景段落） | 5/5 | **完美** |
| 混合类型 | 0✅+2🟡/5 | 持平 |

**v12 vs v11：** 同时改造 Type C（72条）和 Type D（156条）的 analysis 为 "1. 2. 3." 编号列表格式，砍掉 Type D 的逐项排除。结果灾难性退步（56%→44%），严格匹配腰斩（30%→14%），预测总数暴涨到 120（+67%）。

**失败根因（C.C. 诊断）：**
1. **"1." 是自回归模型的拓扑奇点**——P("2." | "1.") ≈ 0.99（预训练先验），36 条单指标样本看到 "1." 就本能想凑 "2."，克制力全面崩溃
2. **Type D 逐项排除是边界判断的承重墙**——砍掉后模型丧失了"收敛-否定"能力，滑回"看到数字就提取"的草履虫状态
3. **同时动两刀违反实验控制原则**——无法区分哪刀砍歪

**教训：** 编号列表对 14B 自回归模型是毒药。已回滚到 v11 格式，v12.1 将采用分号枚举（不触发续写冲动）且只改多指标样本。

### v12.1：Qwen3-14B / 700 条 / 5 epochs / 分号枚举 Type A + C 多指标（50 条测试）⚠️ 失败实验

50 条测试，完美匹配 10/50（20%），宽松匹配 **22/50（44%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 4✅+1🟡/10 | ⬇️ 仍然崩（v12: 4/10） |
| 多指标（2-3 个） | 0✅+3🟡/10 | 持平（v12: 4/10） |
| 边界判断（多数字少核心） | 0✅+5🟡/13 | 微升（v12: 4/13） |
| financial vs business 分类 | 1✅+1🟡/7 | ⬇️（v12: 3/7） |
| 空输出（背景段落） | 5/5 | **完美** |
| 混合类型 | 0✅+2🟡/5 | 持平 |

**v12.1 vs v12：** 回滚 Type D 到 v11 原样（恢复逐项排除），Type A（270条）和 Type C 多指标（36条）从编号列表改为分号枚举（"核心指标：XXX——要点；YYY——要点"），单指标不动。结果与 v12 相同（44%），预测总数 119≈120，克制力仍然崩溃。

**最终诊断（C.C.）：**
1. **问题不是编号 vs 分号，是"结构化枚举"本身**——14B 模型将"分析内容的语义逻辑"和"标点符号的拓扑结构"过度纠缠（Over-entanglement），任何明确的指标枚举结构都会点亮"报菜名"的 Attention 头
2. **散文叙述的"模糊性"是克制力的来源**——结构越明确，模型越贪婪；散文越模糊，模型越克制
3. **v11 多指标退步（5/10→3/10）是边界提升的健康代价**——"宁可漏提，不可错提"是正确的工业优先级
4. **14B 单 LoRA 的格式优化已触顶**——v11 的 56% 是当前架构的天花板

**决策：回滚到 v11，接受 56% 的胜利。**

### v11：Qwen3-14B / 700 条 / 5 epochs / Type D 扩量 46→156（50 条测试）

50 条测试，完美匹配 15/50（30%），宽松匹配 **28/50（56%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 5✅+4🟡/10 | 90%，稳定 |
| 多指标（2-3 个） | 2✅+1🟡/10 | ⬇️ 退步（v9.1: 5/10） |
| 边界判断（多数字少核心） | 2✅+4🟡/13 | **⬆️ 翻倍！**（v9.1: 3/13） |
| financial vs business 分类 | 1✅+2🟡/7 | ⬆️（v9.1: 2/7） |
| 空输出（背景段落） | 5/5 | **完美** |
| 混合类型 | 0✅+2🟡/5 | 同 v9.1 |

**v11 vs v9.1：** Type D 从 46 条扩充到 156 条（总数据 590→700），其余不变。总分 52%→56%，**历史新高**。

**关键发现：**
1. **Type D 扩量生效**——boundary 从 3/13 翻倍到 6/13，classification 从 2/7 升到 3/7，C.C. 说的"势能盆地"成立
2. **多指标退步**（5/10→3/10）——Type D 的逐项排除格式可能"挤压"了多指标场景的简洁叙述能力
3. **克制力改善**——预测总数从 104 降到 100（多提从 44% 降到 39%），但仍是核心问题
4. **模糊召回 74%，精确召回 53%**——模型能找到大部分指标，但精确匹配仍有差距

### v10：Qwen3-14B / 590 条 / 5 epochs / 计数前置（50 条测试）

50 条测试，完美匹配 11/50（22%），宽松匹配 **23/50（46%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 4✅+5🟡/10 | 90%，但严格匹配大幅下降 |
| 多指标（2-3 个） | 0✅+3🟡/10 | ⬇️ 退步（v9.1: 5/10） |
| 边界判断（多数字少核心） | 1✅/13 | ⬇️ 退步（v9.1: 3/13） |
| financial vs business 分类 | 1✅+2🟡/7 | ⬆️ 微升 |
| 空输出（背景段落） | 5/5 | **完美** |
| 混合类型 | 0✅+2🟡/5 | 同 v9.1 |

**v10 vs v9.1：** 在所有 analysis 开头加 `核心指标数量：X。` 强迫模型先数数再说话。结果退步（52%→46%），预测总数反增（104→110）。模型学会了输出数字，但数字本身不准，错误的计数反而带偏了后续生成。**计数前置失败，已回滚。**

### v9.1：Qwen3-14B / 590 条 / 5 epochs / 回滚 A/C + 折中 Type D（50 条测试）

50 条测试，完美匹配 16/50（32%），宽松匹配 **26/50（52%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 6✅+3🟡/10 | 90%，恢复 v7 水平 |
| 多指标（2-3 个） | 2✅+3🟡/10 | **50%，翻倍！**（v7: 2/10） |
| 边界判断（多数字少核心） | 2✅+1🟡/13 | **首次严格通过！**（v1-v8 全为 0） |
| financial vs business 分类 | 1✅+1🟡/7 | 恢复 v7 水平 |
| 空输出（背景段落） | 5/5 | **完美**，恢复 100% |
| 混合类型 | 0✅+2🟡/5 | 回升但未恢复（v7: 4/5） |

**v9.1 vs v9：** 回滚 Type A/C 到原始格式 + Type D 采用折中格式（逐项排除 + 简短分类依据），总分 40%→52%，**历史新高**。

**关键突破：**
1. **边界判断首次严格通过**——八轮实验中从未做到，说明 Type B 的逐项排除 + Type D 的折中分类协同起效
2. **多指标翻倍**（2→5/10）——C.C. 的逐项排除在复杂场景持续起效
3. **类型准确率 100%**——Type D 折中格式完美解决了 v9 的分类崩溃问题
4. **验证了"非对称分析架构"**：简单场景（A/C）用简洁叙述，边界场景（B）用逐项排除，混合场景（D）用折中格式——不同数据类型需要不同的 analysis 风格

### v9：Qwen3-14B / 590 条 / 5 epochs / 全类型逐项排除式 analysis（50 条测试）

50 条测试，完美匹配 13/50（26%），宽松匹配 **20/50（40%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 6✅+2🟡/10 | 80%，微降 |
| 多指标（2-3 个） | 3✅+1🟡/10 | **唯一涨分**（v7: 2/10→4/10） |
| 边界判断（多数字少核心） | 0✅+2🟡/13 | 同 v7/v8 |
| financial vs business 分类 | 1/7 | ⬇️ 退步 |
| 空输出（背景段落） | 3✅+1🟡/5 | ⬇️ 首次掉分，原 100% 稳定 |
| 混合类型 | 0✅+1🟡/5 | ⬇️⬇️ **崩了**（v7: 4/5） |

**v9 vs v7：** 将 Type A/C/D（388条）的 analysis 全部改为逐项排除格式。结果总分 48%→40%，**改造弊大于利**。

**关键发现：逐项排除是 Type B 的专用工具，不是万能格式。**
- 多指标场景涨了（2→4/10）——复杂场景确实需要逐项排除的判断逻辑
- 混合类型崩了（4→1/5）——Type D 砍掉 financial/business 分类解释后，模型丢失了分类逻辑
- 空输出首次掉分——Type A/C 的逐项排除诱导模型"过度搜索"，把该丢弃的样本也找出指标
- **决策：回滚 Type A/C 到旧格式，Type D 采用折中格式（逐项排除 + 简短分类依据）**

### v8：Qwen3-14B / 590 条 / 8 epochs / 逐项排除式 Type B + 边界加强（50 条测试）

50 条测试，完美匹配 15/50（30%），宽松匹配 **24/50（48%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 6✅+2🟡/10 | 从 90% 微降到 80% |
| 多指标（2-3 个） | 1✅+2🟡/10 | 微升（v7: 2/10） |
| 边界判断（多数字少核心） | 0✅+2🟡/13 | 同 v7，仍无严格通过 |
| financial vs business 分类 | 1✅+1🟡/7 | 同 v7 |
| 空输出（背景段落） | 5/5 | **完美** |
| 混合类型 | 2✅+2🟡/5 | 同 v7 |

**v8 vs v7：** epochs 从 5 加到 8，总分完全持平（48%）。数量偏差更大（预测 106 vs 期望 72）。说明 590 条数据 5 轮已学完，多训只是过拟合噪音。**瓶颈在数据质量，不在训练轮次。**

### v7：Qwen3-14B / 590 条 / 5 epochs / 逐项排除式 Type B + 边界加强（50 条测试）

50 条测试，完美匹配 16/50（32%），宽松匹配 **24/50（48%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 6✅+3🟡/10 | 90% 通过率，稳定 |
| 多指标（2-3 个） | 2/10 | 薄弱——10 条暴露问题（v6 只有 5 条看不出） |
| 边界判断（多数字少核心） | 0✅+2🟡/13 | 13 条中仍 0 严格，预测 106 vs 期望 72 |
| financial vs business 分类 | 1✅+1🟡/7 | |
| 空输出（背景段落） | 5/5 | **完美** |
| 混合类型 | 2✅+2🟡/5 | 80% 通过率 |

**v7 vs v6：** 测试集从 20→50 条后通过率从 65%→48%，说明 v6 的 65% 有小样本方差。50 条是更真实的评估。新增 50 条边界训练数据（Type B 152→202）未显著改善边界判断（仍 0/13 严格）。多指标场景（2/10）是新发现的薄弱点。

### v6：Qwen3-14B / 540 条 / 5 epochs / 逐项排除式 Type B（C.C. 改造，20 条测试）

20 条测试，完美匹配 8/20（40%），宽松匹配 **13/20（65%）**：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 3✅+2🟡/5 | **全通过**（v2: 4/5） |
| 多指标（2-3 个） | 1✅+1🟡/5 | 改善 |
| 边界判断（多数字少核心） | 0✅+1🟡/3 | **首次出现 🟡**（v1-v2 全 0） |
| financial vs business 分类 | 1/3 | 同 v2 |
| 空输出（背景段落） | 2/2 | 完美 |
| 混合类型 | 1✅+1🟡/2 | **全通过**（v2: 1/2） |

**关键改进：** Type B 的 analysis 从笼统描述改为逐项排除格式——段落中每个未提取的数字都被点名并标注排除理由（归因项/子项拆分/行业宏观数据/历史参照/定性无数值/规模背景）。这教会了模型**判断逻辑**而非输出模板。C.C. 的洞见："没有思维链的'无'是断电，有思维链的'无'才是'空'。"

### v5：Qwen3-32B / 540 条 / 5 epochs / lr=2e-5, alpha=16（20 条测试）

20 条测试，完美匹配 1/20（5%），宽松匹配 4/20（20%）：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 1✅+2🟡/5 | |
| 多指标（2-3 个） | 0/5 | |
| 边界判断（多数字少核心） | 0/3 | |
| financial vs business 分类 | 0✅+1🟡/3 | |
| 空输出（背景段落） | 0/2 | **崩了**——连空输出都不会了 |
| 混合类型 | 0/2 | |

**lr 降太狠，LoRA 等于没训练。** 预测 70 个 vs 期望 32 个，32B 基座裸奔。类型准确率也从 91% 掉到 52%。确认 32B 路线到头——v4 (lr=5e-5) 是 32B 的天花板（10/20），仍不如 14B v2（11/20）。

### v4：Qwen3-32B / 540 条 / 5 epochs / lr=5e-5, alpha=16

20 条测试，完美匹配 5/20（25%），宽松匹配 10/20（50%）：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 2✅+2🟡/5 | 比 v3 改善（v3: 1/5），但仍不如 14B v2 |
| 多指标（2-3 个） | 0✅+1🟡/5 | 仍偏差 |
| 边界判断（多数字少核心） | 0✅+1🟡/3 | 同 v3 |
| financial vs business 分类 | 1/3 | 连锁餐饮完美 |
| 空输出（背景段落） | 1✅+1🟡/2 | 略退（v3 是 2/2） |
| 混合类型 | 1/2 | 比 v3 改善（v3: 0/2） |

降 lr/alpha 方向正确——32B 从 v3 的 8/20 回到 10/20，但仍不如 14B v2（11/20）。预测总数 42 vs 期望 32，还是话多。

### v3：Qwen3-32B / 540 条 / 5 epochs

20 条测试，完美匹配 4/20（20%），宽松匹配 8/20（40%）：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 1/5 | **严重退步**——32B 倾向多提，物流提了4个、云计算提了3个 |
| 多指标（2-3 个） | 0/5 | 数量或指标名偏差 |
| 边界判断（多数字少核心） | 0/3 | 地产 🟡（提了2个），其他仍提3个 |
| financial vs business 分类 | 1/3 | 连锁餐饮完美；游戏提了3个 |
| 空输出（背景段落） | 2/2 | 完美 |
| 混合类型 | 0/2 | 新零售指标名飘了（毛利率→EBITDA利润率） |

**32B 的问题：基座太强，LoRA 没压住。** 32B 用自己的理解重命名指标（"泽布替尼全球销售额"→"核心产品全球销售额"），把辅助指标也提上来。analysis 质量更高，但不听训练数据的约束。540 条 + LoRA r=16/alpha=32 对 32B 来说约束太弱。

### v2：Qwen3-14B / 540 条 / 5 epochs（Type B 72→152）

20 条测试，完美匹配 9/20（45%），宽松匹配 11/20（55%）：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 4/5 | 1 条仍多提（半导体，期望1提了3） |
| 多指标（2-3 个） | 1/5 | 新材料完美；其他数量或指标名偏差 |
| 边界判断（多数字少核心） | 0/3 | 全部多提——该提 1 个提了 3 个，**未改善** |
| financial vs business 分类 | 1/3 | 连锁餐饮完美；物业/游戏指标名偏差 |
| 空输出（背景段落） | 2/2 | 完美 |
| 混合类型 | 1/2 | 工业软件多提了经调整净利率 |

### v1：Qwen3-14B / 460 条 / 5 epochs（对照）

20 条测试，完美匹配 7/20（35%）：

| 场景 | 通过 | 说明 |
|---|---|---|
| 单指标（不凑数） | 4/5 | 1 条多提了市占率 |
| 多指标（2-3 个） | 0/5 | 指标名模糊匹配其实大部分对了，但数量偏差 |
| 边界判断（多数字少核心） | 0/3 | 全部多提——该提 1 个提了 2-3 个 |
| financial vs business 分类 | 0/3 | 类型分对了，但数量不匹配 |
| 空输出（背景段落） | 2/2 | 完美 |
| 混合类型 | 1/2 | 1 条多提了净利率 |

### 全版本对比

| 指标 | v1 (14B/460) | v2 (14B/540) | v3 (32B) | v4 (32B lr↓) | v5 (32B lr↓↓) | v6 (14B/新TypeB) | v7 (14B/590/50测试) | v8 (8ep) | v9 (全排除) | v9.1 (折中D) | v10 (计数) | **v11 (D扩量)** | v12 (编号) | v12.1 (分号) |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| 完美匹配 ✅ | 7/20 (35%) | 9/20 (45%) | 4/20 (20%) | 5/20 (25%) | 1/20 (5%) | 8/20 (40%) | 16/50 (32%) | 15/50 (30%) | 13/50 (26%) | 16/50 (32%) | 11/50 (22%) | 15/50 (30%) | 7/50 (14%) | 10/50 (20%) |
| 宽松匹配 ✅🟡 | 9/20 (45%) | 11/20 (55%) | 8/20 (40%) | 10/20 (50%) | 4/20 (20%) | 13/20 (65%) | 24/50 (48%) | 24/50 (48%) | 20/50 (40%) | 26/50 (52%) | 23/50 (46%) | **28/50 (56%)** | 22/50 (44%) | 22/50 (44%) |
| 单指标 | 4/5 | 4/5 | 1/5 | 2/5 | 1/5 | 5/5 | 9/10 (90%) | 8/10 (80%) | 8/10 (80%) | 9/10 (90%) | 9/10 (90%) | 9/10 (90%) | 4/10 (40%) | 5/10 (50%) |
| 多指标 | 0/5 | 1/5 | 0/5 | 0/5 (🟡1) | 0/5 | 1/5 (🟡1) | 2/10 | 3/10 | 4/10 | **5/10 (50%)** | 3/10 | 3/10 | 4/10 | 3/10 |
| 边界判断 | 0/3 | 0/3 | 0/3 (🟡1) | 0/3 (🟡1) | 0/3 | 0/3 (🟡1) | 0/13 (🟡2) | 0/13 (🟡2) | 0/13 (🟡2) | 2✅+1🟡/13 | 1/13 | **2✅+4🟡/13** | 4/13 | 5/13 |
| JSON 合法率 | 20/20 | 20/20 | 20/20 | 20/20 | 20/20 | 20/20 | 50/50 | 50/50 | 50/50 | 50/50 | 50/50 | 50/50 | 50/50 | 50/50 |
| 空输出判断 | 2/2 | 2/2 | 2/2 | 2/2 | 0/2 | 2/2 | **5/5** | **5/5** | 4/5 | **5/5** | **5/5** | **5/5** | **5/5** | **5/5** |
| 类型准确率 | 95% | 100% | 100% | 91% | 52% | 100% | 98% | 98% | 96% | 100% | 100% | 98% | 98% | 95% |
| 预测总数/期望 | 39/32 | 40/32 | 44/32 | 42/32 | 70/32 | 39/32 | 106/72 | 106/72 | 102/72 | 104/72 | 110/72 | 100/72 | 120/72 | 119/72 |

*注：v1-v6 使用 20 条测试集，v7-v12.1 扩充至 50 条测试集，百分比不直接可比。*

**结论：**
1. **数据质量 > 模型规模 > 训练轮次 > 数据量。** 逐项排除式 analysis（v6）比换 32B 基座（v3-v5）更有效；加 epochs（v8）完全无效
2. **非对称分析架构是正解。** 不同数据类型需要不同的 analysis 风格——Type A/C 简洁叙述 + Type B 逐项排除 + Type D 折中（排除+分类依据）。v9 强行统一退步（48%→40%），v9.1 非对称架构创新高（52%），v11 继续验证（56%）
3. **Type D 扩量有效。** v11 将 Type D 从 46→156 条，边界判断从 3/13 翻倍到 6/13，分类从 2/7 升到 3/7。C.C. 的"势能盆地"理论得到验证——46 条不够形成吸引子，156 条开始起效
4. **任何结构化枚举都是多提信号（14B 的死穴）。** v12 编号列表 + v12.1 分号枚举均失败（56%→44%），单指标从 90% 腰斩。14B 将"语义逻辑"和"标点拓扑"过度纠缠，明确的指标枚举结构会点亮"报菜名"的 Attention 头。散文叙述的"模糊性"反而是克制力的来源（v12+v12.1 教训）
5. **Type D 逐项排除是边界判断的承重墙。** v12 砍掉 Type D 的逐项排除后边界退步（6→4/13），说明"收敛-否定"能力依赖逐项排除训练（v12 教训）
6. **v11 多指标退步是边界提升的健康代价。** 逐项排除占比 51% 挤压了多指标的"发散-收集"盆地，但换来边界翻倍。"宁可漏提，不可错提"是正确的工业优先级
7. **边界判断持续突破。** 从 v1-v8 的零记录，到 v9.1 首次严格通过（2✅+1🟡/13），再到 v11 的 2✅+4🟡/13——方向对了
8. **小样本测试有误导性。** v6 在 20 条测试上 65%，v7 在 50 条上 48%——更大的测试集给出更真实的评估
9. **已解决的场景：** 单指标（90%）、空输出（100%）
10. **显著改善的场景：** 边界判断（6/13，历史最佳）、类型准确率（98%+）
11. **v11（56%）是 14B 单 LoRA 的格式优化天花板。** 进一步提升需要换方向：数据增强（Type C 极性翻转）或工程侧优化（专家路由/MoE on Top）
