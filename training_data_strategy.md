# 金融研报指标提取 —— 训练数据策略

## 1. 问题诊断

### 1.0 现有训练集的实际情况（拿到 xlsx 后的分析）

拿到 260 条训练/评估数据后做了详细分析，发现比表面数字严重：

**最大的问题：所有数据永远提 2 个指标**

260 条数据，DeepSeek 标注全部恰好 2 个指标，fine-tuned 模型输出也全部恰好 2 个。没有一条是 1 个或 3 个。这是 prompt 里"数量严格控制：2个"直接导致的——模型学到的不是"该提几个"，而是"必须凑够 2 个"。凑不够就硬编，多了就砍。

**158 条"不一致"的到底差在哪：**

| 类型 | 数量 | 说明 |
|------|------|------|
| 1 个对了、1 个不同 | 115 条 | 第一个指标提对了，第二个对不上 |
| 其中语义很接近被误判 | 45 条 | 如"投资活动现金流" vs "投资活动净现金流"（相似度 0.93） |
| 两个都不同 | 43 条 | 完全没对上 |

真实例子：
- "运维业务收入" vs "排水管网及泵站运维业务收入" → 判不一致（其实是同一个东西）
- "在手未完工合同" vs "在手未完工合同储备" → 判不一致（相似度 0.88）
- "投资活动现金流" vs "投资活动净现金流" → 判不一致（相似度 0.93）

**结论：**
1. **"必须提 2 个"是最大的毒药**——很多段落只有 1 个核心指标，硬凑第二个就是噪声，模型学到的是凑数
2. **DeepSeek 的标注本身有问题**——它也在硬凑第二个，作为 ground truth 质量不够
3. **字符串精确匹配让准确率虚低**——语义相同但写法不同的被误判，真实准确率可能高 10-15 个百分点

### 1.1 "提几个"和"提什么"被混在一起训练

| 模型 | 症状 | 根因 |
|------|------|------|
| Qwen3-32B（零样本） | key 多了 102 行 | 不知道什么不该提，疯狂过度提取 |
| Finetuned Qwen3-14B | key 少了 61 行（23%） | 学会了"少提比多提安全"，矫枉过正 |

本质：模型学到了"提 2 个"这个死规则，而不是"这段话有几个值得提的"。

### 1.2 混合类型 14% 的根因是任务定义模糊

- financial 和 business 的边界本身就不清晰（"经营获现能力"算哪个？）
- 标注者（DeepSeek）自己可能也不一致
- 混合类型 = 两个模糊边界叠加 = 噪声翻倍

### 1.3 评估标准太严导致信号失真

- "完美匹配"要求 metric_name 字符串完全一致
- "债务结构" vs "债务水平" —— 语义相同但判为错误
- 实测：45 条因为命名差异被误判为"不一致"，真实准确率可能比报表高 10-15 个百分点

## 2. 解决方案：三刀策略

### 第一刀：让模型先"想"再"提"

**之前**：段落 → JSON（端到端，模型在猜）

**之后**：段落 → analysis + metrics（带理由的输出）

```json
{
  "analysis": "本段主要分析偿债能力。'债务结构'被专门拆解，是分析主体。'经营获现能力'是解释偿债能力的原因，排除。",
  "metrics": [
    {"metric_name": "债务结构", "metric_type": "financial", "score": 0.95, "reason": "被专门拆解分析"}
  ]
}
```

为什么有效：
- `analysis` 强制模型先理解段落结构，再决定提什么
- `reason` 让每个提取决定可追溯——出错时能定位是"理解错了"还是"判断错了"
- 训练时模型学的是**判断逻辑**，不只是输出模板

### 第二刀：四类训练样本

不只要正样本，需要四类：

| 类型 | 占比 | 目的 | 数量建议 |
|------|------|------|----------|
| **A: 标准正样本** | 60% | 正常提取 2-3 个指标 | 300 条 |
| **B: 边界负样本** | 15% | 教"什么不该提"（诱饵段落） | 80 条 |
| **C: 数量变化样本** | 15% | 打破"永远提 2 个"的死模式 | 80 条 |
| **D: 混合类型专项** | 10% | 专练 financial/business 分类 | 50 条 |

**Type B 示例**（段落里有诱饵）：
```
段落："受益于产品结构优化和原材料成本下降，公司毛利率同比提升2.3个百分点"
analysis："'产品结构优化'和'原材料成本下降'是原因，不是分析主体。只有'毛利率'被评价。"
→ 只提 1 个：毛利率
```

**Type C 示例**（数量不固定）：
- 短段落只分析 ROE 一个指标 → 只输出 1 个
- 长段落从营收/毛利率/费用率/净利率四维度分析 → 输出 4 个

**Type D 示例**（混合类型）：
```
同店销售增长率 → business（市场地位指标）
毛利率 → financial（财务表现指标）
analysis 里明确解释分类理由
```

### 第三刀：改评估方法

扔掉"完美匹配"作为唯一指标，改用三层评估：

| 层级 | 指标 | 含义 |
|------|------|------|
| L1 核心命中率 | Recall（语义匹配） | 标注里的核心指标，模型提到了几个？ |
| L2 精确率/召回率 | Precision + Recall + F1 | 多提了什么、漏了什么？ |
| L3 类型准确率 | Type Accuracy | 在命中的前提下，financial/business 分对了吗？ |

语义匹配方案（替代字符串精确匹配）：
- **简单版**：编辑距离 + 子串包含（eval_script.py 已实现，零依赖）
- **进阶版**：用 sentence-transformers 做 embedding 余弦相似度 > 0.85

## 3. 数据生成流程

### 数据来源
- 上市公司年报/半年报（巨潮资讯网）
- 券商研报（东方财富、同花顺）
- 10-20 家公司，覆盖不同行业即可

### 生成方法
1. 从真实研报中截取段落（每段 3-10 句话）
2. 用 DeepSeek/Claude 做第一轮标注（带 analysis 的完整格式）
3. **人工校验重点放在 Type B 和 Type D**——这两类标注质量直接决定模型能不能学会边界判断
4. 数据增强：对同一段落做多版本标注，让模型见到合理的分歧

### 数据量
- **总计约 500 条**，按四类比例分配
- 比大而糙的 1000 条更有效——quality > quantity

## 4. 交付物清单

| 文件 | 说明 |
|------|------|
| `training_data_strategy.md` | 本文档 |
| `sample_data.jsonl` | 50 条 demo 训练数据（Type A×30 + B×8 + C×8 + D×4） |
| `eval_script.py` | 三层评估脚本（支持 fuzzy / embedding 两种匹配） |

### eval_script.py 用法

```bash
# 基本用法（模糊匹配，零依赖）
python eval_script.py --pred predictions.jsonl --gold gold.jsonl

# 语义匹配（需要 pip install sentence-transformers）
python eval_script.py --pred predictions.jsonl --gold gold.jsonl --method embedding

# 查看每条样本详情
python eval_script.py --pred predictions.jsonl --gold gold.jsonl --detail
```

## 5. 落地建议

1. **先用 50 条 demo 数据试跑一轮**，看模型能否学会 analysis 格式
2. **重点关注 Type B 和 Type C 的效果**——如果模型在这两类上有进步，说明策略方向对了
3. **评估时先看 F1，再看完美匹配率**——F1 比完美匹配率更能反映真实进步
4. **如果 Type D（混合类型）效果依然差**，考虑把 financial/business 分类做成第二步独立任务
